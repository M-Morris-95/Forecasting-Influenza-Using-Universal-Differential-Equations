{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43c71f4-c633-48ab-88ab-434c3afa8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "# Data handling and numerical computations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import interpolate\n",
    "\n",
    "# PyTorch related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical, Normal, kl_divergence\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "# Visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utilities and custom modules\n",
    "from itertools import chain\n",
    "import lib.utils as utils\n",
    "import lib.models as models\n",
    "import lib.train_functions as train_functions\n",
    "import lib.encoders as encoders\n",
    "from lib.HHS_data import *\n",
    "import tqdm\n",
    "\n",
    "# Setting the number of threads for PyTorch and specifying the device\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# root = 'checkpoints/HHS_SIR_Big/'   \n",
    "# enc.load_state_dict(torch.load(root+'enc_' + '.pth'))\n",
    "# ode.load_state_dict(torch.load(root+'sir_' + '.pth'))\n",
    "# dec.load_state_dict(torch.load(root+'dec_' + '.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf90721-671b-4cdb-8b00-7a666854755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(x_in, y_in, t, n_samples = 128, dtype = torch.float32):\n",
    "    batch_size = x_in.shape[0]\n",
    "    eps = torch.randn(n_samples, batch_size, n_regions, latent_dim-1, dtype=dtype, device=device)\n",
    "    ode.clear_tracking()\n",
    "    mean, std = enc(x_in)\n",
    "    z = reparam(eps, std, mean, n_samples, batch_size)\n",
    "    latent = odeint(ode, z, t, method='rk4', options=dict(step_size = 1.0))\n",
    "    y_pred = dec(latent[..., :3]).reshape((t.shape[0], n_samples, batch_size, n_regions)).permute(2,1,0,3)\n",
    "\n",
    "    nll = train_functions.nll_loss(y_pred, y_in).detach().cpu().numpy()\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d645b6-6af6-4bdf-a028-0f2359d862df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Encoder_BiDirectionalGRU(n_regions, \n",
    "#                          n_qs=n_qs,\n",
    "#                          latent_dim = latent_dim-1,    \n",
    "#                          q_sizes=q_sizes, \n",
    "#                          ili_sizes=ili_sizes, \n",
    "#                          ff_sizes = ff_sizes, \n",
    "#                          SIR_scaler = SIR_scaler, \n",
    "#                          device=device, \n",
    "#                          dtype=torch.float32)\n",
    "\n",
    "# enc = Encoder_MISO_GRU(n_regions = n_regions,\n",
    "#                        n_qs=n_qs,\n",
    "#                        latent_dim=latent_dim-1, \n",
    "#                        q_sizes=q_sizes, \n",
    "#                        ili_sizes=ili_sizes, \n",
    "#                        ff_sizes = ff_sizes, \n",
    "#                        SIR_scaler = SIR_scaler,\n",
    "#                        device=device, \n",
    "#                        dtype=torch.float32)\n",
    "\n",
    "# enc = Encoder_Back_GRU(n_regions=n_regions, \n",
    "#                        input_size=n_qs+1, \n",
    "#                        latent_dim = latent_dim-1, \n",
    "#                        q_sizes=q_sizes, \n",
    "#                        ili_sizes=ili_sizes, \n",
    "#                        ff_sizes = ff_sizes, \n",
    "#                        SIR_scaler = SIR_scaler, \n",
    "#                        device=device, \n",
    "#                        dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc0bd9-0312-45e7-890a-e706a854e52c",
   "metadata": {},
   "source": [
    "**Get prior working better - choose sigma1 and sigma2:**\n",
    "- [0.1, 0.01]\n",
    "- [0.05, 0.005]\n",
    "  \n",
    "**Encoder Architecture:**\n",
    "- GRU MISO Bidirectional\n",
    "- GRU SISO Backwards\n",
    "- GRU Bidirectional\n",
    "  \n",
    "**Prior Sigma1/2:**\n",
    "- [0.1, 0.01]\n",
    "- [0.05, 0.005]\n",
    "  \n",
    "**ODE:**\n",
    "- HHS SIR\n",
    "- HHS SIR Fa\n",
    "  \n",
    "**Decoder:**\n",
    "- Single Layer FF\n",
    "  \n",
    "**Epochs:**\n",
    "- 1000\n",
    "  \n",
    "**Latent Dim:**\n",
    "- 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec632c8-15bf-4150-a5dc-41eefda23570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable\n",
    "n_qs = 5\n",
    "window = 42\n",
    "latent_dim = 6\n",
    "batch_size = 32\n",
    "means=[0.8, 0.55]\n",
    "stds = [0.2, 0.2]\n",
    "ff_sizes = [64,32]\n",
    "ili_sizes = [32, 16]\n",
    "SIR_scaler = [0.1, 0.05, 1.0]\n",
    "q_sizes=[128, 64]\n",
    "\n",
    "encoder_model = encoders.Encoder_BiDirectionalGRU\n",
    "# encoder_model = encoders.Encoder_MISO_GRU\n",
    "# encoder_model = encoders.Encoder_Back_GRU\n",
    "\n",
    "lag = 14\n",
    "n_regions = 10\n",
    "season = 2016\n",
    "lr = 1e-3\n",
    "n_samples = 128\n",
    "epochs = 1000\n",
    "\n",
    "root = 'checkpoints/HHS_SIR_Big_new/'      \n",
    "device = 'cpu'\n",
    "dtype=torch.float32\n",
    "\n",
    "tmax = 8\n",
    "\n",
    "if encoder_model == encoders.Encoder_Back_GRU:   \n",
    "    gamma = 28\n",
    "    t = torch.linspace(1,gamma+window, gamma+window, device=device)/7\n",
    "    \n",
    "else:\n",
    "    gamma = 63\n",
    "    t = torch.linspace(1,gamma, gamma, device=device)/7\n",
    "eval_pts = [0,6,13,20,27,34,40,47,54][:tmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b214b8a5-9c2a-4d5e-b533-2df313de6061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "ili = load_ili('hhs')\n",
    "ili = intepolate_ili(ili)\n",
    "\n",
    "hhs_dict = {}\n",
    "qs_dict = {}\n",
    "\n",
    "ignore = ['AZ', 'ND', 'AL', 'RI', 'VI', 'PR']\n",
    "for i in range(1,1+n_regions):\n",
    "    hhs_dict[i] = get_hhs_query_data(i, ignore=ignore, smooth_after = True)\n",
    "    qs_dict[i] = choose_qs(hhs_dict, ili, i, season, n_qs)\n",
    "\n",
    "    hhs_dict[i] = hhs_dict[i].loc[:, list(qs_dict[i])]\n",
    "    hhs_dict[i] = hhs_dict[i].div(hhs_dict[i].max())\n",
    "    \n",
    "ili = ili.loc[hhs_dict[i].index[0] : hhs_dict[i].index[-1]]\n",
    "ili = ili.div(ili.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a48f1d1-db78-4574-93e5-7a8ae1444737",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backward = False\n",
    "if encoder_model == encoders.Encoder_Back_GRU:\n",
    "    run_backward = True\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "for batch in range(ili.shape[0] - (window+gamma)):\n",
    "    batch_inputs = []\n",
    "    for i in range(1,11):\n",
    "        batch_inputs.append(hhs_dict[i].iloc[batch:batch+window])\n",
    "    \n",
    "    t_ili = ili.iloc[batch:batch+window].copy()\n",
    "    t_ili.iloc[-lag:, :] = -1\n",
    "    batch_inputs.append(t_ili)\n",
    "    batch_inputs = np.concatenate(batch_inputs, -1)\n",
    "\n",
    "    if run_backward:\n",
    "        gamma = 28\n",
    "        batch_outputs = ili.iloc[batch:batch+window-lag+gamma].values\n",
    "        t = torch.linspace(1, batch_outputs.shape[0], batch_outputs.shape[0])/7\n",
    "    else:\n",
    "        gamma = 56\n",
    "        batch_outputs = ili.iloc[batch+window-lag:batch+window-lag+gamma].values\n",
    "        t = torch.linspace(1, batch_outputs.shape[0], batch_outputs.shape[0])/7\n",
    "        \n",
    "    inputs.append(batch_inputs)\n",
    "    outputs.append(batch_outputs)\n",
    "inputs = torch.tensor(np.asarray(inputs), dtype=torch.float32)\n",
    "outputs = torch.tensor(np.asarray(outputs), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07be425d-2fd9-488d-b574-9a1379f78d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters: 283172\n",
      "ode parameters: 9364\n",
      "decoder parameters: 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_835142/3982467524.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_train.append(torch.tensor(x_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))\n",
      "/tmp/ipykernel_835142/3982467524.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train.append(torch.tensor(y_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "enc = encoder_model(n_regions, \n",
    "             n_qs=n_qs,\n",
    "             latent_dim = latent_dim-1,    \n",
    "             q_sizes=q_sizes, \n",
    "             ili_sizes=ili_sizes, \n",
    "             ff_sizes = ff_sizes, \n",
    "             SIR_scaler = SIR_scaler, \n",
    "             device=device, \n",
    "             dtype=torch.float32)\n",
    "\n",
    "ode = models.Fp(n_regions, latent_dim, nhidden=64)\n",
    "dec = models.Decoder(n_regions, 3, 1, device=device)\n",
    "\n",
    "enc.to(device)\n",
    "ode.to(device)\n",
    "dec.to(device)\n",
    "\n",
    "num = np.sum([np.prod(_.shape) for _ in list(enc.parameters())])\n",
    "print('encoder parameters:', num)\n",
    "\n",
    "num = np.sum([np.prod(_.shape) for _ in list(ode.parameters())])\n",
    "print('ode parameters:', num)\n",
    "\n",
    "num = np.sum([np.prod(_.shape) for _ in list(dec.parameters())])\n",
    "print('decoder parameters:', num)\n",
    "\n",
    "batch_size = 32\n",
    "new_inputs = torch.tensor(np.asarray(inputs), dtype=torch.float32).to(device)\n",
    "new_outputs = torch.tensor(np.asarray(outputs), dtype=torch.float32).to(device)\n",
    "\n",
    "train_size = len(new_inputs) - 365\n",
    "x_tr, y_tr = new_inputs[:train_size], new_outputs[:train_size]\n",
    "x_test, y_test = new_inputs[train_size:], new_outputs[train_size:]\n",
    "\n",
    "# batch it all \n",
    "x_train = []\n",
    "y_train = []\n",
    "for b in range(int(np.ceil(x_tr.shape[0]/batch_size))):\n",
    "    x_train.append(torch.tensor(x_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))\n",
    "    y_train.append(torch.tensor(y_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d694a5d-c701-4121-b7bd-905c50197eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:10<00:00, 16.85it/s, Epoch=0, KL_z=9.73]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(enc.parameters(), lr=lr)\n",
    "for epoch in range(3):\n",
    "    kls = 0\n",
    "    pbar = tqdm.tqdm(x_train)\n",
    "    num = 0\n",
    "    for x_tr in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mean, std = enc(x_tr)\n",
    "        prior = encoders.make_prior(mean, latent_dim=latent_dim, device=device)\n",
    "        kl = kl_divergence(Normal(mean, std), prior).mean(0).sum()\n",
    "        if torch.isnan(kl):\n",
    "            break\n",
    "        kl.backward()\n",
    "        optimizer.step()\n",
    "        kls += kl.cpu().detach().numpy()\n",
    "        num += 1\n",
    "        pbar.set_postfix({'Epoch':epoch, 'KL_z':kls/num})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bfa14-a666-4bed-9306-02fde84ed377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [03:09,  1.07s/it, loss=786, nll=5.86, kl_latent=4.83, kl_params=5.93, reg_loss=770, lr=0.001]         \n",
      "176it [03:15,  1.11s/it, loss=1.99, nll=0.54, kl_latent=0.0255, kl_params=1.3, reg_loss=0.12, lr=0.000999]    \n",
      "176it [03:33,  1.21s/it, loss=0.826, nll=0.0129, kl_latent=0.0242, kl_params=0.742, reg_loss=0.0464, lr=0.000998]  \n",
      "176it [03:47,  1.29s/it, loss=0.446, nll=-.24, kl_latent=0.0184, kl_params=0.571, reg_loss=0.0974, lr=0.000997] \n",
      "176it [03:35,  1.22s/it, loss=0.133, nll=-.411, kl_latent=0.0173, kl_params=0.507, reg_loss=0.0202, lr=0.000996]  \n",
      "176it [03:35,  1.23s/it, loss=-.00745, nll=-.499, kl_latent=0.0164, kl_params=0.461, reg_loss=0.0134, lr=0.000995] \n",
      "176it [03:57,  1.35s/it, loss=0.0261, nll=-.461, kl_latent=0.0151, kl_params=0.412, reg_loss=0.0597, lr=0.000994] \n",
      "176it [04:06,  1.40s/it, loss=-.181, nll=-.559, kl_latent=0.0159, kl_params=0.351, reg_loss=0.0114, lr=0.000993] \n",
      "176it [04:19,  1.47s/it, loss=-.268, nll=-.587, kl_latent=0.0142, kl_params=0.289, reg_loss=0.0165, lr=0.000992] \n",
      "176it [03:55,  1.34s/it, loss=-.334, nll=-.578, kl_latent=0.013, kl_params=0.224, reg_loss=0.00696, lr=0.000991] \n",
      "176it [04:06,  1.40s/it, loss=-.417, nll=-.609, kl_latent=0.0131, kl_params=0.171, reg_loss=0.00745, lr=0.00099]\n",
      "176it [04:22,  1.49s/it, loss=-.421, nll=-.591, kl_latent=0.0138, kl_params=0.129, reg_loss=0.0269, lr=0.000989] \n",
      "176it [04:49,  1.64s/it, loss=-.478, nll=-.598, kl_latent=0.013, kl_params=0.104, reg_loss=0.00317, lr=0.000988] \n",
      "176it [04:28,  1.52s/it, loss=-.54, nll=-.633, kl_latent=0.0127, kl_params=0.0795, reg_loss=0.00095, lr=0.000987]  \n",
      "176it [04:41,  1.60s/it, loss=-.563, nll=-.638, kl_latent=0.0119, kl_params=0.0596, reg_loss=0.00435, lr=0.000986]\n",
      "176it [04:45,  1.62s/it, loss=-.559, nll=-.63, kl_latent=0.0114, kl_params=0.044, reg_loss=0.0154, lr=0.000985]  \n",
      "176it [06:13,  2.12s/it, loss=-.596, nll=-.639, kl_latent=0.0112, kl_params=0.0304, reg_loss=0.00093, lr=0.000984] \n",
      "176it [08:20,  2.84s/it, loss=-.608, nll=-.64, kl_latent=0.0113, kl_params=0.0191, reg_loss=0.00188, lr=0.000983] \n",
      "176it [08:23,  2.86s/it, loss=-.619, nll=-.643, kl_latent=0.0109, kl_params=0.0117, reg_loss=0.00098, lr=0.000982] \n",
      "176it [20:50,  7.11s/it, loss=-.617, nll=-.639, kl_latent=0.011, kl_params=0.00691, reg_loss=0.00454, lr=0.000981] \n",
      "54it [09:34,  9.22s/it, loss=-.761, nll=-.779, kl_latent=0.0109, kl_params=0.00656, reg_loss=0.00117, lr=0.00098]"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(chain(enc.parameters(), ode.parameters(), dec.parameters()), lr=lr)\n",
    "_history = train_functions.history()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm.tqdm(zip(x_train, y_train))\n",
    "    for x_tr, y_tr in pbar:\n",
    "        batch_size = x_tr.shape[0]\n",
    "        eps = torch.randn(n_samples, batch_size, n_regions, latent_dim-1, dtype=dtype, device=device)\n",
    "        ode.clear_tracking()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mean, std = enc(x_tr)\n",
    "        z = encoders.reparam(eps, std, mean, n_samples, batch_size)\n",
    "        latent = odeint(ode, z, t, method='rk4', options=dict(step_size = 1.0))\n",
    "        y_pred = dec(latent[..., :3]).reshape((-1, n_samples, batch_size, n_regions)).permute(2,1,0,3)\n",
    "\n",
    "        # nll = train_functions.nll_loss(y_pred, y_tr[:, eval_pts, :])\n",
    "        nll = train_functions.nll_loss(y_pred, y_tr)\n",
    "        kl_p = train_functions.get_kl_params(1, ode.posterior(), means=means, stds = stds,limit = 1e6, device=device)\n",
    "        kl_z = kl_divergence(encoders.make_prior(mean, latent_dim=latent_dim, device=device), Normal(mean, std)).sum(-1).mean() / len(x_train)\n",
    "        reg_loss = train_functions.latent_init_loss(latent[..., :3])\n",
    "\n",
    "        loss = nll+kl_p+kl_z+reg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _history.batch([loss.cpu(), nll.cpu(), kl_z.cpu(),kl_p.cpu(),reg_loss.cpu(), optimizer.param_groups[-1]['lr']], ['loss', 'nll', 'kl_latent', 'kl_params', 'reg_loss', 'lr'])\n",
    "        pbar.set_postfix(_history.epoch())\n",
    "    _history.reset()\n",
    "        \n",
    "    utils.update_learning_rate(optimizer, 0.999, lr/10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c5f4d-e3fd-42aa-8446-2030917ee274",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(x_test, y_test, t, n_samples = 128, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7c85f-872c-4e5d-9177-408ad953b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc.load_state_dict(torch.load(root+'enc_' + '.pth'))\n",
    "# ode.load_state_dict(torch.load(root+'sir_' + '.pth'))\n",
    "# dec.load_state_dict(torch.load(root+'dec_' + '.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
