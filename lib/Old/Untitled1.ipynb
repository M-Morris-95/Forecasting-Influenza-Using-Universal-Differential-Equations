{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "17aefe98-c09b-4a66-848c-6eee8bb01d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "# Data handling and numerical computations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import interpolate\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def smooth(df, n=7):\n",
    "    smoothed = pd.DataFrame(index = df.index[n:], \n",
    "                            columns = df.columns, \n",
    "                            data = np.mean(np.asarray([df[i:-(n-i)] for i in range(n)]), 0))\n",
    "    return smoothed       \n",
    "\n",
    "def get_state_query_data(num, root = '../google_queries/', append = 'state_queries_new', ignore = [], return_all = False, smooth_after = False):\n",
    "    state_codes = {'AK':'Alaska','AL':'Alabama','AR':'Arkansas','AZ':'Arizona','CA':'California','CO':'Colorado','CT':'Connecticut','DE':'Delaware','DC':'District of Columbia','GA':'Georgia','HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas','KY':'Kentucky','LA':'Louisiana','ME':'Maine','MD':'Maryland','MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana','NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico','NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma','OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina','SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont','VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'}\n",
    "    \n",
    "    code = list(state_codes.keys())[num-1]\n",
    "    \n",
    "    df = pd.read_csv(root+append +'/'+code+'_query_data.csv', index_col=0, parse_dates=True)\n",
    "           \n",
    "    if smooth_after:\n",
    "        df = smooth(df)\n",
    "        \n",
    "    return df    \n",
    "\n",
    "def get_hhs_query_data(num, root = '../google_queries/', append = 'state_queries_new', ignore = [], return_all = False, smooth_after = False):\n",
    "    state_pop = pd.read_csv(root + 'state_population_data_2019.csv', index_col = 0)\n",
    "    state_dict =  {1:['CT', 'ME', 'MT', 'NH', 'RI', 'VT'],\n",
    "                   2:['NY', 'NJ'],\n",
    "                   3:['DE', 'MD', 'PA', 'VA', 'WV', 'DC'],\n",
    "                   4:['AL', 'FL', 'GA', 'KY', 'MS', 'NC', 'SC', 'TN'],\n",
    "                   5:['IL', 'IN', 'OH', 'MI', 'MN', 'WI'],\n",
    "                   6:['AR', 'LA', 'NM', 'OK', 'TX'],\n",
    "                   7:['IA', 'KS', 'MO', 'NE'],\n",
    "                   8:['CO', 'MT', 'ND', 'SD', 'UT', 'WY'],\n",
    "                   9:['AZ', 'CA', 'HI', 'NV'],\n",
    "                  10:['AK', 'ID', 'OR', 'WA']}\n",
    "    \n",
    "    total_population = sum([state_pop[state_pop['CODE'] == code]['POP'].values[0] for code in state_dict[num]])\n",
    "    \n",
    "    dfs = []\n",
    "    for code in state_dict[num]:\n",
    "        if code not in ignore:\n",
    "            population = state_pop[state_pop['CODE'] == code]['POP'].values[0]/total_population\n",
    "            new_nf = population*pd.read_csv(root+append +'/'+code+'_query_data.csv', index_col=0, parse_dates=True)\n",
    "            dfs.append(new_nf)\n",
    "    \n",
    "    cols = [d.columns for d in dfs]\n",
    "    common_cols = cols[0]\n",
    "    for col_list in cols[1:]:\n",
    "        common_cols = common_cols.intersection(col_list)\n",
    "    \n",
    "    idxs = [d.index for d in dfs]\n",
    "    common_idxs = idxs[0]\n",
    "    for idx_list in idxs[1:]:\n",
    "        common_idxs = common_idxs.intersection(idx_list)\n",
    "    \n",
    "    df = pd.DataFrame(index = common_idxs, columns = common_cols, data = 0)\n",
    "        \n",
    "    for d in dfs:\n",
    "        df = df+d.loc[df.index, df.columns]\n",
    "\n",
    "    if smooth_after:\n",
    "        df = smooth(df)\n",
    "        \n",
    "    if return_all:\n",
    "        return df, dfs\n",
    "    return df    \n",
    "\n",
    "def choose_qs(df, daily_ili, region_num, season, n_qs, region='hhs'):\n",
    "    state_codes = {'AK':'Alaska','AL':'Alabama','AR':'Arkansas','AZ':'Arizona','CA':'California','CO':'Colorado','CT':'Connecticut','DE':'Delaware','DC':'District of Columbia','GA':'Georgia','HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas','KY':'Kentucky','LA':'Louisiana','ME':'Maine','MD':'Maryland','MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana','NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico','NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma','OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina','SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont','VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'}\n",
    "    queries = df[region_num]\n",
    "\n",
    "    if region == 'hhs':\n",
    "        ili = daily_ili['Region '+str(region_num)]\n",
    "    elif region == 'state':\n",
    "        ili = daily_ili[state_codes[list(state_codes.keys())[region_num-1]]]\n",
    "        \n",
    "    index = daily_ili.index.intersection(queries.index)\n",
    "    queries = queries.loc[index]\n",
    "    ili = ili.loc[index]\n",
    "    \n",
    "    dates = pd.date_range(dt.date(season-3, 10, 3), dt.date(season,10,1))\n",
    "\n",
    "    queries_subset = queries.loc[dates].std()\n",
    "    queries = queries.iloc[:, np.where(queries_subset != 0)[0]]\n",
    "\n",
    "    corr_df = pd.DataFrame(index=queries.columns,\n",
    "                 columns=['correlation'],\n",
    "                 data=[pearsonr(ili.loc[dates].squeeze(), q)[0] for q in\n",
    "                               queries.loc[dates].values.T])\n",
    "    scores = pd.read_csv('Data/Similarity_Scores.csv', index_col=0)\n",
    "    scores['correlation'] = corr_df\n",
    "    scores = scores.dropna()\n",
    "    \n",
    "    for col in scores.columns:\n",
    "        scores[col] = scores[col] - scores[col].min()\n",
    "        scores[col] = scores[col] / scores[col].max()\n",
    "        scores[col] = 1 - scores[col]\n",
    "    scores['score'] = np.sqrt(np.square(scores).sum(1))\n",
    "    \n",
    "    scores = scores.sort_values('score')\n",
    "    \n",
    "    query_choice = scores[:n_qs]\n",
    "    return query_choice.index\n",
    "\n",
    "def load_ili(location):\n",
    "    location_dict = {'US':'Data/national_flu.csv',\n",
    "                     'England':'Data/England_ILIrates.csv',\n",
    "                     'state':'Data/state_flu.csv',\n",
    "                     'hhs':'Data/hhs_flu.csv'}\n",
    "    \n",
    "    ili = pd.read_csv(location_dict[location], index_col = -1, parse_dates=True)\n",
    "    if location == 'state' or location =='hhs':\n",
    "        new_ili = pd.DataFrame()\n",
    "        for region in ili['region'].unique():\n",
    "            new_ili[region] = ili[ili['region'] == region]['unweighted_ili']\n",
    "        ili = new_ili\n",
    "        ili /= 13\n",
    "        ili= ili.fillna(0)\n",
    "        \n",
    "    if location == 'US':\n",
    "        # ili[['weighted_ili']].rename(columns = {'weighted_ili':'National'})\n",
    "        ili = ili[['weighted_ili']]\n",
    "        ili /= 13\n",
    "    \n",
    "    if location == 'England':\n",
    "        ili['Date'] = [dt.datetime.strptime(d, '%d/%m/%Y')+dt.timedelta(days=3) for d in ili['ISOWeekStartDate'].values]\n",
    "        ili = ili[['Date', 'RatePer100000']].set_index('Date')\n",
    "        ili = ili.rename(columns = {'RatePer100000':'National'})\n",
    "\n",
    "    return ili\n",
    "\n",
    "def intepolate_ili(ili, fill_1=False):\n",
    "    dates = np.asarray([ili.index[0] + dt.timedelta(days=i) for i in\n",
    "                    range((ili.index[-1] - ili.index[0]).days + 1)])\n",
    "\n",
    "    x = np.linspace(0, 1, ili.shape[0])\n",
    "    x2 = np.linspace(0, 1, dates.shape[0])\n",
    "    f = interpolate.interp1d(x, ili.values, axis = 0, kind = 'cubic')\n",
    "\n",
    "    if not fill_1:\n",
    "        return pd.DataFrame(index=dates, columns=ili.columns, data=f(x2))\n",
    "    else:\n",
    "        return pd.DataFrame(index=dates, columns=ili.columns, data=ili).fillna(-1)\n",
    "\n",
    "class DataConstructor:\n",
    "    def __init__(self, test_season, region = 'hhs', window_size = 28, n_queries = 10, gamma = 28, window = 28, lag = 14, n_regions=10, fill_1 = False, root = 'checkpoints/HHS_SIR_Big_new/' ):\n",
    "\n",
    "        self.lag = lag\n",
    "        self.window = window\n",
    "        self.root = root\n",
    "        self.n_regions = n_regions\n",
    "        self.test_season = test_season\n",
    "        self.region = region\n",
    "        self.window_size = window_size\n",
    "        self.n_queries = n_queries\n",
    "        self.gamma = gamma\n",
    "        self.fill_1 = fill_1\n",
    "\n",
    "        if region == 'hhs':\n",
    "            self.n_regions = 10\n",
    "        elif region == 'state':\n",
    "            self.n_regions = 49\n",
    "\n",
    "    def __call__(self, run_backward=False, no_qs_in_output=False):\n",
    "        state_codes = {'AK':'Alaska','AL':'Alabama','AR':'Arkansas','AZ':'Arizona','CA':'California','CO':'Colorado',\n",
    "                       'CT':'Connecticut','DE':'Delaware','DC':'District of Columbia','GA':'Georgia',\n",
    "                       'HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas','KY':'Kentucky',\n",
    "                       'LA':'Louisiana','ME':'Maine','MD':'Maryland','MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana','NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico','NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma','OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina','SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont','VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'}\n",
    "        ili = load_ili(self.region)\n",
    "        ili = intepolate_ili(ili, fill_1 = fill_1)\n",
    "\n",
    "        qs_data_dict = {}\n",
    "        qs_names_dict = {}\n",
    "        ignore = ['VI', 'PR']\n",
    "\n",
    "        for i in range(1,1+self.n_regions):\n",
    "            if self.region == 'hhs':\n",
    "                qs_data_dict[i] = get_hhs_query_data(i, ignore=ignore, smooth_after = True)\n",
    "            elif self.region == 'state':\n",
    "                qs_data_dict[i] = get_state_query_data(i, ignore=ignore, smooth_after = True)\n",
    "\n",
    "            qs_names_dict[i] = choose_qs(qs_data_dict, ili, i, self.test_season-1, self.n_queries, region = self.region)\n",
    "            qs_data_dict[i] = qs_data_dict[i].loc[:, list(qs_names_dict[i])]\n",
    "            qs_data_dict[i] = qs_data_dict[i].div(qs_data_dict[i].max())\n",
    "\n",
    "        ili = ili.loc[qs_data_dict[i].index[0] : qs_data_dict[i].index[-1]]\n",
    "        if self.region == 'state':\n",
    "            ili = ili[list(state_codes.values())]\n",
    "\n",
    "        scaler = ili.max()*13\n",
    "        ili = ili.div(ili.max())\n",
    "\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        dates = []\n",
    "        for batch in range(self.window+1, ili.shape[0] - (self.gamma)):\n",
    "            batch_inputs = []\n",
    "            for i in range(1,1+self.n_regions):\n",
    "                batch_inputs.append(qs_data_dict[i].iloc[batch-self.window-1:batch+self.lag-1])\n",
    "            \n",
    "            t_ili = ili.iloc[batch-self.window-1:batch+self.lag-1].copy()\n",
    "            t_ili.iloc[-self.lag:, :] = -1\n",
    "\n",
    "            batch_inputs.append(t_ili)\n",
    "            batch_inputs = np.concatenate(batch_inputs, -1)\n",
    "\n",
    "            \n",
    "            batch_outputs = []\n",
    "            for i in range(1,1+self.n_regions):\n",
    "                if run_backward:\n",
    "                    batch_outputs.append(qs_data_dict[i].iloc[batch-self.window-1:batch+self.gamma])     \n",
    "                    t_ili = ili.iloc[batch-self.window-1:batch+self.gamma].copy()\n",
    "                else:\n",
    "                    batch_outputs.append(qs_data_dict[i].iloc[batch:batch+self.gamma])            \n",
    "                    t_ili = ili.iloc[batch:batch+self.gamma].copy()\n",
    "            \n",
    "            batch_outputs.append(t_ili)\n",
    "            batch_outputs = np.concatenate(batch_outputs, -1) \n",
    "\n",
    "            if no_qs_in_output:\n",
    "                batch_outputs = batch_outputs[..., -self.n_regions:]\n",
    "                \n",
    "            dates.append((t_ili.index[0]-dt.timedelta(days=1)).to_pydatetime())\n",
    "            inputs.append(batch_inputs)\n",
    "            outputs.append(batch_outputs)\n",
    "\n",
    "        train_test_dates = pd.read_csv('Data/Dates.csv', index_col=0).loc[self.test_season]\n",
    "\n",
    "        train_start = dt.datetime.strptime(train_test_dates['train_start'], '%Y-%m-%d')\n",
    "        train_end = dt.datetime.strptime(train_test_dates['train_end'], '%Y-%m-%d')\n",
    "        test_start = dt.datetime.strptime(train_test_dates['test_start'], '%Y-%m-%d')\n",
    "        test_end = dt.datetime.strptime(train_test_dates['test_end'], '%Y-%m-%d')\n",
    "\n",
    "        try:\n",
    "            train_start = np.where([train_start == d for d in dates])[0][0]\n",
    "        except:\n",
    "            train_start = 0\n",
    "        \n",
    "        train_end = np.where([train_end == d for d in dates])[0][0]\n",
    "        test_start = np.where([test_start == d for d in dates])[0][0]\n",
    "        test_end = np.where([test_end == d for d in dates])[0][0]\n",
    "\n",
    "        x_train = np.asarray(inputs[train_start:train_end])\n",
    "        y_train = np.asarray(outputs[train_start:train_end])\n",
    "        x_test = np.asarray(inputs[test_start:test_end])\n",
    "        y_test = np.asarray(outputs[test_start:test_end])\n",
    "\n",
    "        return x_train, y_train, x_test, y_test, scaler\n",
    "    \n",
    "def convert_to_torch(x_train, y_train, x_test, y_test, batch_size=32, shuffle=True, dtype=torch.float32):\n",
    "        x_train = torch.tensor(x_train, dtype = dtype)\n",
    "        y_train = torch.tensor(y_train, dtype = dtype)\n",
    "        x_test = torch.tensor(x_test, dtype = dtype)\n",
    "        y_test = torch.tensor(y_test, dtype = dtype)\n",
    "\n",
    "        train_dataset = TensorDataset(x_train, y_train)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        return train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed2ae9ae-a597-4d0c-b6e9-2b1b2ecf0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    _data = DataConstructor(test_season=2016, region = 'hhs', window_size=28, n_queries=9, gamma=28)\n",
    "    x_train, y_train, x_test, y_test, _ = _data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5caf93ae-328a-4609-93ec-aca861f33caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4a4f1b45-f2b5-4fb8-b1a2-9f4a85cb8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dict = {'US':'Data/national_flu.csv',\n",
    "                 'England':'Data/England_ILIrates.csv',\n",
    "                 'state':'Data/state_flu.csv',\n",
    "                 'hhs':'Data/hhs_flu.csv'}\n",
    "\n",
    "ili = pd.read_csv(location_dict[location], index_col = -1, parse_dates=True)\n",
    "if location == 'state' or location =='hhs':\n",
    "    new_ili = pd.DataFrame()\n",
    "    for region in ili['region'].unique():\n",
    "        new_ili[region] = ili[ili['region'] == region]['unweighted_ili']\n",
    "    ili = new_ili\n",
    "    ili /= 13\n",
    "    ili= ili.fillna(0)\n",
    "    \n",
    "if location == 'US':\n",
    "    ili = ili['weighted_ili']\n",
    "    # ili[['weighted_ili']].rename(columns = {'weighted_ili':'National'})\n",
    "    ili /= 13\n",
    "\n",
    "if location == 'England':\n",
    "    ili['Date'] = [dt.datetime.strptime(d, '%d/%m/%Y')+dt.timedelta(days=3) for d in ili['ISOWeekStartDate'].values]\n",
    "    ili = ili[['Date', 'RatePer100000']].set_index('Date')\n",
    "    ili = ili.rename(columns = {'RatePer100000':'National'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "58ecac39-61db-4226-a7fa-f2c63eb75700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_ili</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-09-28</th>\n",
       "      <td>0.084729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-05</th>\n",
       "      <td>0.092313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-12</th>\n",
       "      <td>0.106058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-19</th>\n",
       "      <td>0.092246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-26</th>\n",
       "      <td>0.127398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-23</th>\n",
       "      <td>0.077045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-30</th>\n",
       "      <td>0.070565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-06</th>\n",
       "      <td>0.079195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-13</th>\n",
       "      <td>0.075061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-20</th>\n",
       "      <td>0.081431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            weighted_ili\n",
       "week_start              \n",
       "1997-09-28      0.084729\n",
       "1997-10-05      0.092313\n",
       "1997-10-12      0.106058\n",
       "1997-10-19      0.092246\n",
       "1997-10-26      0.127398\n",
       "...                  ...\n",
       "2020-08-23      0.077045\n",
       "2020-08-30      0.070565\n",
       "2020-09-06      0.079195\n",
       "2020-09-13      0.075061\n",
       "2020-09-20      0.081431\n",
       "\n",
       "[1200 rows x 1 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_ili('US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a1e29933-6f01-4520-bf22-7133b16fc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dates = pd.read_csv('Data/Dates.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e8e0ad79-ec1d-4ef6-b5cd-6d9c57c6bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = dt.datetime.strptime(train_test_dates.loc[2015, 'test_start'], '%Y-%m-%d')\n",
    "test_end = dt.datetime.strptime(train_test_dates.loc[2015, 'test_end'], '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4e5cce2b-f22e-4c40-8550-af6780f3b6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_ili</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-30</th>\n",
       "      <td>0.066205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-06</th>\n",
       "      <td>0.068208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>0.077573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-20</th>\n",
       "      <td>0.082019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-27</th>\n",
       "      <td>0.081535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-04</th>\n",
       "      <td>0.094276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11</th>\n",
       "      <td>0.100820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-18</th>\n",
       "      <td>0.105469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-25</th>\n",
       "      <td>0.107055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-01</th>\n",
       "      <td>0.110548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-08</th>\n",
       "      <td>0.115512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-15</th>\n",
       "      <td>0.122927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-22</th>\n",
       "      <td>0.145898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-29</th>\n",
       "      <td>0.129022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-06</th>\n",
       "      <td>0.137151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-13</th>\n",
       "      <td>0.144105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-20</th>\n",
       "      <td>0.178575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-27</th>\n",
       "      <td>0.185378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.149483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-10</th>\n",
       "      <td>0.153689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-17</th>\n",
       "      <td>0.162945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-24</th>\n",
       "      <td>0.173163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-31</th>\n",
       "      <td>0.182397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-07</th>\n",
       "      <td>0.215412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-14</th>\n",
       "      <td>0.243442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-21</th>\n",
       "      <td>0.242448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-28</th>\n",
       "      <td>0.256315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-06</th>\n",
       "      <td>0.273865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-13</th>\n",
       "      <td>0.234984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-20</th>\n",
       "      <td>0.212871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>0.187816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>0.156422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>0.152764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>0.147318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>0.130745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-01</th>\n",
       "      <td>0.121258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-08</th>\n",
       "      <td>0.107192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-15</th>\n",
       "      <td>0.099955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-22</th>\n",
       "      <td>0.091061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-29</th>\n",
       "      <td>0.087479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-05</th>\n",
       "      <td>0.080091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            weighted_ili\n",
       "week_start              \n",
       "2015-08-30      0.066205\n",
       "2015-09-06      0.068208\n",
       "2015-09-13      0.077573\n",
       "2015-09-20      0.082019\n",
       "2015-09-27      0.081535\n",
       "2015-10-04      0.094276\n",
       "2015-10-11      0.100820\n",
       "2015-10-18      0.105469\n",
       "2015-10-25      0.107055\n",
       "2015-11-01      0.110548\n",
       "2015-11-08      0.115512\n",
       "2015-11-15      0.122927\n",
       "2015-11-22      0.145898\n",
       "2015-11-29      0.129022\n",
       "2015-12-06      0.137151\n",
       "2015-12-13      0.144105\n",
       "2015-12-20      0.178575\n",
       "2015-12-27      0.185378\n",
       "2016-01-03      0.149483\n",
       "2016-01-10      0.153689\n",
       "2016-01-17      0.162945\n",
       "2016-01-24      0.173163\n",
       "2016-01-31      0.182397\n",
       "2016-02-07      0.215412\n",
       "2016-02-14      0.243442\n",
       "2016-02-21      0.242448\n",
       "2016-02-28      0.256315\n",
       "2016-03-06      0.273865\n",
       "2016-03-13      0.234984\n",
       "2016-03-20      0.212871\n",
       "2016-03-27      0.187816\n",
       "2016-04-03      0.156422\n",
       "2016-04-10      0.152764\n",
       "2016-04-17      0.147318\n",
       "2016-04-24      0.130745\n",
       "2016-05-01      0.121258\n",
       "2016-05-08      0.107192\n",
       "2016-05-15      0.099955\n",
       "2016-05-22      0.091061\n",
       "2016-05-29      0.087479\n",
       "2016-06-05      0.080091"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "05076678-2007-4d7d-a87b-ba725105b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "33532e24-85a0-4384-a51f-1f55d6ae6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ili = load_ili('US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "69b96b5b-5500-4154-8c1c-54f54ffc6283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>hhs</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.810441</td>\n",
       "      <td>0.930066</td>\n",
       "      <td>0.95344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.843001</td>\n",
       "      <td>0.933858</td>\n",
       "      <td>0.963886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.899874</td>\n",
       "      <td>0.951228</td>\n",
       "      <td>0.968715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.948775</td>\n",
       "      <td>0.965883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state       hhs        US\n",
       "2015  0.810441  0.930066   0.95344\n",
       "2016  0.843001  0.933858  0.963886\n",
       "2017  0.899874  0.951228  0.968715\n",
       "2018    0.8819  0.948775  0.965883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>hhs</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.691289</td>\n",
       "      <td>0.835865</td>\n",
       "      <td>0.868466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.753258</td>\n",
       "      <td>0.835249</td>\n",
       "      <td>0.888716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.785778</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.885441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.77495</td>\n",
       "      <td>0.855273</td>\n",
       "      <td>0.88901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state       hhs        US\n",
       "2015  0.691289  0.835865  0.868466\n",
       "2016  0.753258  0.835249  0.888716\n",
       "2017  0.785778  0.847096  0.885441\n",
       "2018   0.77495  0.855273   0.88901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>hhs</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.551381</td>\n",
       "      <td>0.718821</td>\n",
       "      <td>0.76229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.635841</td>\n",
       "      <td>0.72029</td>\n",
       "      <td>0.785575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.663391</td>\n",
       "      <td>0.714122</td>\n",
       "      <td>0.769793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.640237</td>\n",
       "      <td>0.739665</td>\n",
       "      <td>0.790215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state       hhs        US\n",
       "2015  0.551381  0.718821   0.76229\n",
       "2016  0.635841   0.72029  0.785575\n",
       "2017  0.663391  0.714122  0.769793\n",
       "2018  0.640237  0.739665  0.790215"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:197: RuntimeWarning: invalid value encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>hhs</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.387529</td>\n",
       "      <td>0.568578</td>\n",
       "      <td>0.625442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.509458</td>\n",
       "      <td>0.598821</td>\n",
       "      <td>0.671534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.511503</td>\n",
       "      <td>0.565863</td>\n",
       "      <td>0.633189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610976</td>\n",
       "      <td>0.675965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state       hhs        US\n",
       "2015  0.387529  0.568578  0.625442\n",
       "2016  0.509458  0.598821  0.671534\n",
       "2017  0.511503  0.565863  0.633189\n",
       "2018       NaN  0.610976  0.675965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lag in [1,2,3,4]:\n",
    "    autocorr = pd.DataFrame(index = [2015, 2016, 2017, 2018], columns = ['state', 'hhs', 'US'])\n",
    "    for season in [2015, 2016, 2017, 2018]:\n",
    "        test_start = dt.datetime.strptime(train_test_dates.loc[season, 'test_start'], '%Y-%m-%d')\n",
    "        test_end = dt.datetime.strptime(train_test_dates.loc[season, 'test_end'], '%Y-%m-%d')\n",
    "        for region in ['state', 'hhs', 'US']:\n",
    "            ili = load_ili(region)\n",
    "            ili = ili.loc[test_start:test_end]\n",
    "            \n",
    "            # Compute autocorrelation for all columns and store in a new DataFrame\n",
    "            autocorr_results = pd.DataFrame(index=['autocorr'])\n",
    "            for column in ili.columns:\n",
    "                if not np.isnan(ili[column].autocorr()):\n",
    "                    autocorr_results[column] = ili[column].autocorr(lag = lag)\n",
    "            \n",
    "            autocorr_results = autocorr_results.T\n",
    "            # print(autocorr_results.mean())\n",
    "    \n",
    "            autocorr.loc[season, region] = gmean(autocorr_results).item()\n",
    "\n",
    "    display(autocorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0ddd37ad-f08b-4cc1-8b42-aeeebf9ac2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>hhs</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.710288</td>\n",
       "      <td>0.836399</td>\n",
       "      <td>0.868466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.760659</td>\n",
       "      <td>0.835958</td>\n",
       "      <td>0.888716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.791813</td>\n",
       "      <td>0.847863</td>\n",
       "      <td>0.885441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.784443</td>\n",
       "      <td>0.855945</td>\n",
       "      <td>0.88901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state       hhs        US\n",
       "2015  0.710288  0.836399  0.868466\n",
       "2016  0.760659  0.835958  0.888716\n",
       "2017  0.791813  0.847863  0.885441\n",
       "2018  0.784443  0.855945   0.88901"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocorr.loc[season, region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a9ceb34c-37e8-4e21-8fc1-9b582d6d0b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 0.9328161356660474,\n",
       " 'Alaska': 0.8699698461677982,\n",
       " 'Arizona': 0.9475584412319107,\n",
       " 'Arkansas': 0.9143484256732253,\n",
       " 'California': 0.9408048681125751,\n",
       " 'Colorado': 0.9627669154262793,\n",
       " 'Connecticut': 0.9572684539782085,\n",
       " 'Delaware': 0.888227057304938,\n",
       " 'District of Columbia': 0.8894641306628152,\n",
       " 'Florida': nan,\n",
       " 'Georgia': 0.9448457941622108,\n",
       " 'Hawaii': 0.9250866371710722,\n",
       " 'Idaho': 0.8798663090539671,\n",
       " 'Illinois': 0.9528789149717682,\n",
       " 'Indiana': 0.9166022426671017,\n",
       " 'Iowa': 0.8115362850859874,\n",
       " 'Kansas': 0.9610733640622768,\n",
       " 'Kentucky': 0.9580285307469838,\n",
       " 'Louisiana': 0.9563945483295858,\n",
       " 'Maine': 0.918491619219672,\n",
       " 'Maryland': 0.8526173535247382,\n",
       " 'Massachusetts': 0.9483440978520052,\n",
       " 'Michigan': 0.9411452021693946,\n",
       " 'Minnesota': 0.8862675221422462,\n",
       " 'Mississippi': 0.9385898772638469,\n",
       " 'Missouri': 0.9369541540186395,\n",
       " 'Montana': 0.9169062601484708,\n",
       " 'Nebraska': 0.8993062015856974,\n",
       " 'Nevada': 0.917564460161929,\n",
       " 'New Hampshire': 0.9125407600919784,\n",
       " 'New Jersey': 0.9507965318536851,\n",
       " 'New Mexico': 0.9337011593892117,\n",
       " 'New York': 0.9447168199871362,\n",
       " 'North Carolina': 0.9114268156518416,\n",
       " 'North Dakota': 0.8567072864664499,\n",
       " 'Ohio': 0.9143025254803842,\n",
       " 'Oklahoma': 0.9350037215546481,\n",
       " 'Oregon': 0.9049560292608706,\n",
       " 'Pennsylvania': 0.9374092872456692,\n",
       " 'Rhode Island': 0.9439077876847527,\n",
       " 'South Carolina': 0.9552262639362583,\n",
       " 'South Dakota': 0.9398639191377246,\n",
       " 'Tennessee': 0.9301704727872739,\n",
       " 'Texas': 0.9478592269022765,\n",
       " 'Utah': 0.9312597424059208,\n",
       " 'Vermont': 0.8945223502064629,\n",
       " 'Virginia': 0.9548343272615393,\n",
       " 'Washington': 0.9250242126155751,\n",
       " 'West Virginia': 0.9313742718425606,\n",
       " 'Wisconsin': 0.9233932713760107,\n",
       " 'Wyoming': 0.933030291536491,\n",
       " 'New York City': 0.9453723998786218,\n",
       " 'Virgin Islands': 0.6940891926491125,\n",
       " 'Puerto Rico': 0.914015400148092,\n",
       " 'Commonwealth of the Northern Mariana Islands': nan}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocorr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07448076-8218-4eba-8be4-017901ae687d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e0d6a6e-93a6-43d2-88a4-f81b72e31851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates = np.asarray([ili.index[0] + dt.timedelta(days=i) for i in\n",
    "                range((ili.index[-1] - ili.index[0]).days + 1)])\n",
    "\n",
    "x = np.linspace(0, 1, ili.shape[0])\n",
    "x2 = np.linspace(0, 1, dates.shape[0])\n",
    "# f = interpolate.interp1d(x, ili.values, axis = 0, kind = 'cubic')\n",
    "\n",
    "# daily_ili = pd.DataFrame(index=dates, columns=ili.columns, data=f(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1275e923-f14e-41d3-8638-09832acf6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=dates, columns=ili.columns, data=ili).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e740d09f-1ab9-4262-8531-09501f3c3572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Arkansas</th>\n",
       "      <th>California</th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Connecticut</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>District of Columbia</th>\n",
       "      <th>Florida</th>\n",
       "      <th>...</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "      <th>New York City</th>\n",
       "      <th>Virgin Islands</th>\n",
       "      <th>Puerto Rico</th>\n",
       "      <th>Commonwealth of the Northern Mariana Islands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-10-03</th>\n",
       "      <td>0.164213</td>\n",
       "      <td>0.067319</td>\n",
       "      <td>0.051902</td>\n",
       "      <td>0.053543</td>\n",
       "      <td>0.150317</td>\n",
       "      <td>0.050822</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>0.216059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113570</td>\n",
       "      <td>0.087956</td>\n",
       "      <td>0.039234</td>\n",
       "      <td>0.122878</td>\n",
       "      <td>0.035771</td>\n",
       "      <td>0.048685</td>\n",
       "      <td>0.090940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-04</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-05</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-06</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-07</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-17</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-18</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-19</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-20</th>\n",
       "      <td>0.081449</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.054881</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.067678</td>\n",
       "      <td>0.073093</td>\n",
       "      <td>0.080718</td>\n",
       "      <td>0.020414</td>\n",
       "      <td>0.310738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045993</td>\n",
       "      <td>0.057485</td>\n",
       "      <td>0.053095</td>\n",
       "      <td>0.214955</td>\n",
       "      <td>0.076372</td>\n",
       "      <td>0.091958</td>\n",
       "      <td>0.065125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3641 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Alabama    Alaska   Arizona  Arkansas  California  Colorado  \\\n",
       "2010-10-03  0.164213  0.067319  0.051902  0.053543    0.150317  0.050822   \n",
       "2010-10-04 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "2010-10-05 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "2010-10-06 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "2010-10-07 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "2020-09-16 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "2020-09-17 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "2020-09-18 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "2020-09-19 -1.000000 -1.000000 -1.000000 -1.000000   -1.000000 -1.000000   \n",
       "2020-09-20  0.081449  0.049100  0.054881  0.076994    0.067678  0.073093   \n",
       "\n",
       "            Connecticut  Delaware  District of Columbia  Florida  ...  \\\n",
       "2010-10-03     0.006024  0.007702              0.216059      0.0  ...   \n",
       "2010-10-04    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "2010-10-05    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "2010-10-06    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "2010-10-07    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "...                 ...       ...                   ...      ...  ...   \n",
       "2020-09-16    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "2020-09-17    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "2020-09-18    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "2020-09-19    -1.000000 -1.000000             -1.000000     -1.0  ...   \n",
       "2020-09-20     0.080718  0.020414              0.310738      0.0  ...   \n",
       "\n",
       "             Vermont  Virginia  Washington  West Virginia  Wisconsin  \\\n",
       "2010-10-03  0.113570  0.087956    0.039234       0.122878   0.035771   \n",
       "2010-10-04 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "2010-10-05 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "2010-10-06 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "2010-10-07 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "...              ...       ...         ...            ...        ...   \n",
       "2020-09-16 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "2020-09-17 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "2020-09-18 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "2020-09-19 -1.000000 -1.000000   -1.000000      -1.000000  -1.000000   \n",
       "2020-09-20  0.045993  0.057485    0.053095       0.214955   0.076372   \n",
       "\n",
       "             Wyoming  New York City  Virgin Islands  Puerto Rico  \\\n",
       "2010-10-03  0.048685       0.090940             0.0       0.0000   \n",
       "2010-10-04 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "2010-10-05 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "2010-10-06 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "2010-10-07 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "...              ...            ...             ...          ...   \n",
       "2020-09-16 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "2020-09-17 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "2020-09-18 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "2020-09-19 -1.000000      -1.000000            -1.0      -1.0000   \n",
       "2020-09-20  0.091958       0.065125             0.0       0.3652   \n",
       "\n",
       "            Commonwealth of the Northern Mariana Islands  \n",
       "2010-10-03                                           0.0  \n",
       "2010-10-04                                          -1.0  \n",
       "2010-10-05                                          -1.0  \n",
       "2010-10-06                                          -1.0  \n",
       "2010-10-07                                          -1.0  \n",
       "...                                                  ...  \n",
       "2020-09-16                                          -1.0  \n",
       "2020-09-17                                          -1.0  \n",
       "2020-09-18                                          -1.0  \n",
       "2020-09-19                                          -1.0  \n",
       "2020-09-20                                           0.0  \n",
       "\n",
       "[3641 rows x 55 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8f62d-9a1d-40bd-af17-f89e3f6afeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
