{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c71f4-c633-48ab-88ab-434c3afa8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "# Data handling and numerical computations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import interpolate\n",
    "\n",
    "# PyTorch related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical, Normal, kl_divergence\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "# Visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utilities and custom modules\n",
    "from itertools import chain\n",
    "import lib.utils as utils\n",
    "import lib.models as models\n",
    "import lib.train_functions as train_functions\n",
    "from lib.HHS_data import *\n",
    "import tqdm\n",
    "\n",
    "# Setting the number of threads for PyTorch and specifying the device\n",
    "torch.set_num_threads(1)\n",
    "# device = 'cpu'  # Uncomment this line if you want to set the device to CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aede417-f173-4102-a7da-a61a593bb447",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../google_queries/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915ffa17-75d5-43d0-aa69-4e53eb7a74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSING VI and PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a48f1d1-db78-4574-93e5-7a8ae1444737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/data0/mimorris/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "season = 2016\n",
    "n_qs = 5\n",
    "n_regions = 10\n",
    "window = 28\n",
    "gamma = 56\n",
    "lag = 14\n",
    "batch = 0\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "ili = load_ili('hhs')\n",
    "ili = intepolate_ili(ili)\n",
    "\n",
    "hhs_dict = {}\n",
    "qs_dict = {}\n",
    "for i in range(1,1+n_regions):\n",
    "    hhs_dict[i] = get_hhs_query_data(i, smooth_after = True)\n",
    "    qs_dict[i] = choose_qs(hhs_dict, ili, i, season, n_qs)\n",
    "\n",
    "    hhs_dict[i] = hhs_dict[i].loc[:, list(qs_dict[i])]\n",
    "    hhs_dict[i] = hhs_dict[i].div(hhs_dict[i].max())\n",
    "    \n",
    "ili = ili.loc[hhs_dict[i].index[0] : hhs_dict[i].index[-1]]\n",
    "ili = ili.div(ili.max())\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for batch in range(ili.shape[0] - (window+gamma)):\n",
    "    batch_inputs = []\n",
    "    for i in range(1,11):\n",
    "        batch_inputs.append(hhs_dict[i].iloc[batch:batch+window])\n",
    "    \n",
    "    t_ili = ili.iloc[batch:batch+window].copy()\n",
    "    t_ili.iloc[-lag:, :] = -1\n",
    "    batch_inputs.append(t_ili)\n",
    "    batch_inputs = np.concatenate(batch_inputs, -1)\n",
    "    \n",
    "    batch_outputs = ili.iloc[batch+window-lag:batch+window-lag+gamma].values\n",
    "    \n",
    "    inputs.append(batch_inputs)\n",
    "    outputs.append(batch_outputs)\n",
    "inputs = torch.tensor(np.asarray(inputs), dtype=torch.float32)\n",
    "outputs = torch.tensor(np.asarray(outputs), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119ceb8-0fc1-4a23-bc81-e7362740a0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1528d845-81d8-4e62-af67-49367d5ad9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparam(eps, std, mean, n_samples, batch_size):\n",
    "    z = eps * std + mean\n",
    "    z = torch.concat([torch.abs(z[..., :2]), (1 - torch.abs(z[..., :2]).sum(-1)).unsqueeze(-1), z[..., 2:]], -1)\n",
    "    z = z.reshape((n_samples * batch_size, ) + z.shape[2:])\n",
    "    return z\n",
    "\n",
    "def make_prior(mean, z_prior=torch.tensor([0.1, 0.01]), device='cpu', latent_dim=8):\n",
    "    z_prior=z_prior.to(device)\n",
    "    mean_concat = torch.cat((mean[..., :2]  , torch.zeros_like(mean[..., 2:], device=device)), dim=-1)\n",
    "    std = torch.cat([z_prior[0].unsqueeze(0), z_prior[1].unsqueeze(0), torch.ones(latent_dim - len(z_prior) - 1, device=device)], 0).expand_as(mean_concat)\n",
    "\n",
    "    return Normal(mean_concat, torch.abs(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27206b0c-5403-4dbe-b31a-d18ed2f30471",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_BiDirectionalGRU(nn.Module):\n",
    "    def __init__(self, n_regions, n_qs=10, latent_dim = 6, q_sizes=[128, 64], ili_sizes=[32, 16], ff_sizes = [64,32], SIR_scaler=[0.1, 0.05, 1.0], device='cpu', dtype=torch.float32):\n",
    "        super(Encoder_BiDirectionalGRU, self).__init__()\n",
    "\n",
    "        self.scaler = torch.tensor(SIR_scaler, dtype=dtype, device=device)\n",
    "        self.latent_dim = latent_dim\n",
    "        if latent_dim > len(self.scaler):\n",
    "            extension = self.scaler[-1].repeat(latent_dim - len(self.scaler))\n",
    "            self.scaler = torch.cat([self.scaler, extension])\n",
    "        self.scaler = self.scaler.view(1, -1)\n",
    "        \n",
    "        self.n_regions = n_regions\n",
    "\n",
    "        self.i_layers = nn.ModuleList()\n",
    "        self.i_layers.append(nn.GRU(n_regions, ili_sizes[0], batch_first=True))\n",
    "        for l in range(1, len(ili_sizes)):\n",
    "            self.i_layers.append(nn.GRU(ili_sizes[l-1], ili_sizes[l], batch_first=True))\n",
    "\n",
    "        self.q_layers = nn.ModuleList()\n",
    "        self.q_layers.append(nn.GRU(n_regions * n_qs, q_sizes[0], bidirectional=True, batch_first=True))\n",
    "        for l in range(1, len(q_sizes)):\n",
    "            self.q_layers.append(nn.GRU(q_sizes[l-1], q_sizes[l], bidirectional=True, batch_first=True))\n",
    "\n",
    "        self.ff_layers = nn.ModuleList()\n",
    "        self.ff_layers.append(nn.Linear(q_sizes[-1]*2 + ili_sizes[-1], ff_sizes[0]))\n",
    "        for l in range(1, len(ff_sizes)):\n",
    "            self.ff_layers.append(nn.ReLU())\n",
    "            self.ff_layers.append(nn.Linear(ff_sizes[l-1], ff_sizes[l]))\n",
    "        self.ff_layers.append(nn.Linear(ff_sizes[l], 2 * n_regions * latent_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_qs = x[:, :, :-self.n_regions]\n",
    "        x_ili = x[:, :-14, -self.n_regions:]\n",
    "\n",
    "        for GRU_layer in self.i_layers:\n",
    "            x_ili, _ = GRU_layer(x_ili)\n",
    "\n",
    "        for GRU_layer in self.q_layers:\n",
    "            x_qs, _ = GRU_layer(x_qs)\n",
    "\n",
    "        x_concat = torch.cat([x_ili[:, -1, :], x_qs[:, -1, :]], -1)\n",
    "\n",
    "        for ff_layer in self.ff_layers:\n",
    "            x_concat = ff_layer(x_concat)\n",
    "\n",
    "        mean, std = utils.split_last_dim(x_concat)\n",
    "        mean = mean.reshape(-1, self.n_regions, self.latent_dim)\n",
    "        std = std.reshape(-1, self.n_regions, self.latent_dim)\n",
    "        std = torch.abs(std) * self.scaler\n",
    "        return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dcbc0e7-d904-412a-bd7e-9ad678434afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_MISO_GRU(nn.Module):\n",
    "    def __init__(self, n_regions, input_size=10, latent_dim = 6, q_sizes=[128, 64], ili_sizes=[32, 16], ff_sizes = [64,32], SIR_scaler=[0.1, 0.05, 1.0], device='cpu', dtype=torch.float32):\n",
    "        super(Encoder_MISO_GRU, self).__init__()\n",
    "\n",
    "        n_qs = input_size-1\n",
    "        self.scaler = torch.tensor(SIR_scaler, dtype=dtype, device=device)\n",
    "        self.latent_dim = latent_dim\n",
    "        if latent_dim > len(self.scaler):\n",
    "            extension = self.scaler[-1].repeat(latent_dim - len(self.scaler))\n",
    "            self.scaler = torch.cat([self.scaler, extension])\n",
    "        self.scaler = self.scaler.view(1, -1)\n",
    "        \n",
    "        self.n_regions = n_regions\n",
    "\n",
    "        self.i_layers = nn.ModuleList()\n",
    "        self.i_layers.append(nn.GRU(n_regions, ili_sizes[0], batch_first=True))\n",
    "        for l in range(1, len(ili_sizes)):\n",
    "            self.i_layers.append(nn.GRU(ili_sizes[l-1], ili_sizes[l], batch_first=True))\n",
    "\n",
    "        self.q_layers = nn.ModuleList()\n",
    "        self.q_layers.append(nn.GRU(n_regions * n_qs, q_sizes[0], bidirectional=True, batch_first=True))\n",
    "        for l in range(1, len(q_sizes)):\n",
    "            self.q_layers.append(nn.GRU(2*q_sizes[l-1], q_sizes[l], bidirectional=True, batch_first=True))\n",
    "\n",
    "        self.ff_layers = nn.ModuleList()\n",
    "        self.ff_layers.append(nn.Linear(q_sizes[-1]*2 + ili_sizes[-1], ff_sizes[0]))\n",
    "        for l in range(1, len(ff_sizes)):\n",
    "            self.ff_layers.append(nn.ReLU())\n",
    "            self.ff_layers.append(nn.Linear(ff_sizes[l-1], ff_sizes[l]))\n",
    "        self.ff_layers.append(nn.Linear(ff_sizes[l], 2 * n_regions * latent_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_qs = x[:, :, :-self.n_regions]\n",
    "        x_ili = x[:, :-14, -self.n_regions:]\n",
    "\n",
    "        for GRU_layer in self.i_layers:\n",
    "            x_ili, _ = GRU_layer(x_ili)\n",
    "\n",
    "        for GRU_layer in self.q_layers:\n",
    "            x_qs, _ = GRU_layer(x_qs)\n",
    "        x_concat = torch.cat([x_ili[:, -1, :], x_qs[:, -1, :]], -1)\n",
    "\n",
    "        for ff_layer in self.ff_layers:\n",
    "            x_concat = ff_layer(x_concat)\n",
    "\n",
    "        mean, std = utils.split_last_dim(x_concat)\n",
    "        mean = mean.reshape(-1, self.n_regions, self.latent_dim)\n",
    "        std = std.reshape(-1, self.n_regions, self.latent_dim)\n",
    "        std = torch.abs(std) * self.scaler\n",
    "        return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4eb234e7-e11d-47d9-bdf2-352f5f6991ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder parameters: 282512\n",
      "ode parameters: 8724\n",
      "decoder parameters: 310\n"
     ]
    }
   ],
   "source": [
    "n_regions = 10\n",
    "latent_dim = 6\n",
    "batch_size = 32\n",
    "layer_sizes=[50, 50]\n",
    "n_hidden = 50\n",
    "cuda = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cuda = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "latent_dim=5\n",
    "# enc = Encoder_BiDirectionalGRU(input_size=6, layer_sizes=layer_sizes, n_hidden=n_hidden, latent_dim=latent_dim-1, n_regions = n_regions, device=device)\n",
    "enc = Encoder_MISO_GRU(input_size=6, latent_dim=latent_dim-1, n_regions = n_regions, device=device)\n",
    "\n",
    "ode = models.Fp(n_regions, latent_dim, nhidden=64)\n",
    "dec = models.Decoder(n_regions, 3, 1, device=device)\n",
    "\n",
    "enc.to(device)\n",
    "ode.to(device)\n",
    "dec.to(device)\n",
    "print('')\n",
    "\n",
    "num = np.sum([np.prod(_.shape) for _ in list(enc.parameters())])\n",
    "print('encoder parameters:', num)\n",
    "\n",
    "num = np.sum([np.prod(_.shape) for _ in list(ode.parameters())])\n",
    "print('ode parameters:', num)\n",
    "\n",
    "num = np.sum([np.prod(_.shape) for _ in list(dec.parameters())])\n",
    "print('decoder parameters:', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07be425d-2fd9-488d-b574-9a1379f78d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1611925/2700302144.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_train.append(torch.tensor(x_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))\n",
      "/tmp/ipykernel_1611925/2700302144.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train.append(torch.tensor(y_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "new_inputs = torch.tensor(np.asarray(inputs), dtype=torch.float32).to(device)\n",
    "new_outputs = torch.tensor(np.asarray(outputs), dtype=torch.float32).to(device)\n",
    "\n",
    "train_size = len(new_inputs) - 365\n",
    "x_tr, y_tr = new_inputs[:train_size], new_outputs[:train_size]\n",
    "x_test, y_test = new_inputs[train_size:], new_outputs[train_size:]\n",
    "\n",
    "# batch it all \n",
    "x_train = []\n",
    "y_train = []\n",
    "for b in range(int(np.ceil(x_tr.shape[0]/batch_size))):\n",
    "    x_train.append(torch.tensor(x_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))\n",
    "    y_train.append(torch.tensor(y_tr[b*batch_size:(b+1)*batch_size], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bfb51d7-603d-43b3-a8bd-4b36f1043263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1984, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.i_layers[0](x_train[0][..., -10:])\n",
    "enc.q_layers[0](x_train[0][..., :-10])\n",
    "enc(x_train[-1])[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaff604c-e945-45c1-9dbd-286d99e8576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "means=[0.8, 0.55]\n",
    "stds = [0.2, 0.2]\n",
    "optimizer = torch.optim.Adam(chain(enc.parameters(), ode.parameters(), dec.parameters()), lr=lr)\n",
    "_history = train_functions.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d694a5d-c701-4121-b7bd-905c50197eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [00:06<00:00, 25.34it/s, Epoch=0, KL_z=7.41]\n",
      "100%|██████████| 177/177 [00:06<00:00, 26.63it/s, Epoch=1, KL_z=0.0271]\n",
      "100%|██████████| 177/177 [00:06<00:00, 26.66it/s, Epoch=2, KL_z=0.0109]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(enc.parameters(), lr=lr)\n",
    "for epoch in range(3):\n",
    "    kls = 0\n",
    "    pbar = tqdm.tqdm(x_train)\n",
    "    num = 0\n",
    "    for x_tr in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mean, std = enc(x_tr)\n",
    "        prior = make_prior(mean, latent_dim=latent_dim, device=device)\n",
    "        kl = kl_divergence(Normal(mean, std), prior).mean(0).sum()\n",
    "        if torch.isnan(kl):\n",
    "            break\n",
    "        kl.backward()\n",
    "        optimizer.step()\n",
    "        kls += kl.cpu().detach().numpy()\n",
    "        num += 1\n",
    "        pbar.set_postfix({'Epoch':epoch, 'KL_z':kls/num})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4ebea-06a6-4d86-99fc-c0ecc8305974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = 'checkpoints/HHS_SIR_Big/'      \n",
    "# enc.load_state_dict(torch.load(root+'enc_' + '.pth'))\n",
    "# ode.load_state_dict(torch.load(root+'sir_' + '.pth'))\n",
    "# dec.load_state_dict(torch.load(root+'dec_' + '.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8906c9a-a6f5-4c87-9466-d957eaf272d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0e-3\n",
    "means=[0.8, 0.55]\n",
    "stds = [0.2, 0.2]\n",
    "optimizer = torch.optim.Adam(chain(enc.parameters(), ode.parameters(), dec.parameters()), lr=lr)\n",
    "_history = train_functions.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f3a951a-e249-48d3-a7c7-018b9fe16dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 56, 10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "363d413e-97c4-4855-b125-d951b2a39fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 9, 10])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[:, eval_pts, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f4bfa14-a666-4bed-9306-02fde84ed377",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "177it [00:52,  3.36it/s, loss=-.239, nll=-.345, kl_latent=0.00519, kl_params=0.425, reg_loss=0.0586, lr=0.000998]\n",
      "177it [00:52,  3.35it/s, loss=-.36, nll=-.443, kl_latent=0.00502, kl_params=0.373, reg_loss=0.0408, lr=0.000997] \n",
      "177it [00:53,  3.33it/s, loss=-.434, nll=-.5, kl_latent=0.00464, kl_params=0.322, reg_loss=0.0297, lr=0.000996]  \n",
      "177it [00:52,  3.35it/s, loss=-.534, nll=-.58, kl_latent=0.00439, kl_params=0.265, reg_loss=0.0155, lr=0.000995] \n",
      "177it [00:53,  3.33it/s, loss=-.548, nll=-.601, kl_latent=0.00422, kl_params=0.2, reg_loss=0.0286, lr=0.000994]  \n",
      "177it [00:52,  3.35it/s, loss=-.598, nll=-.635, kl_latent=0.00407, kl_params=0.18, reg_loss=0.014, lr=0.000993]  \n",
      "177it [00:52,  3.35it/s, loss=-.625, nll=-.658, kl_latent=0.00423, kl_params=0.157, reg_loss=0.0136, lr=0.000992]\n",
      "177it [00:53,  3.33it/s, loss=-.645, nll=-.674, kl_latent=0.0043, kl_params=0.121, reg_loss=0.0119, lr=0.000991] \n",
      "177it [00:52,  3.35it/s, loss=-.605, nll=-.647, kl_latent=0.00549, kl_params=0.118, reg_loss=0.0245, lr=0.00099]\n",
      "177it [00:52,  3.35it/s, loss=-.638, nll=-.667, kl_latent=0.00569, kl_params=0.113, reg_loss=0.0116, lr=0.000989] \n",
      "177it [00:53,  3.33it/s, loss=-.685, nll=-.713, kl_latent=0.00562, kl_params=0.106, reg_loss=0.0121, lr=0.000988] \n",
      "177it [00:53,  3.34it/s, loss=-.775, nll=-.795, kl_latent=0.00535, kl_params=0.0858, reg_loss=0.00627, lr=0.000987]\n",
      "177it [00:52,  3.34it/s, loss=-.89, nll=-.912, kl_latent=0.00553, kl_params=0.0812, reg_loss=0.00797, lr=0.000986] \n",
      "177it [00:52,  3.35it/s, loss=-.964, nll=-.997, kl_latent=0.0067, kl_params=0.0964, reg_loss=0.0168, lr=0.000985] \n",
      "177it [00:53,  3.34it/s, loss=-1.01, nll=-1.03, kl_latent=0.00742, kl_params=0.109, reg_loss=0.00196, lr=0.000984]\n",
      "177it [00:52,  3.36it/s, loss=-1.06, nll=-1.09, kl_latent=0.00717, kl_params=0.11, reg_loss=0.00508, lr=0.000983] \n",
      "177it [00:52,  3.37it/s, loss=-1.07, nll=-1.1, kl_latent=0.0077, kl_params=0.113, reg_loss=0.00444, lr=0.000982]  \n",
      "177it [00:52,  3.36it/s, loss=-1.07, nll=-1.09, kl_latent=0.00764, kl_params=0.107, reg_loss=0.00222, lr=0.000981]\n",
      "177it [00:52,  3.35it/s, loss=-1.11, nll=-1.13, kl_latent=0.0075, kl_params=0.105, reg_loss=0.00845, lr=0.00098]  \n",
      "177it [00:52,  3.35it/s, loss=-1.09, nll=-1.11, kl_latent=0.00638, kl_params=0.0998, reg_loss=0.00275, lr=0.000979]\n",
      "177it [00:52,  3.34it/s, loss=-1.13, nll=-1.15, kl_latent=0.00712, kl_params=0.108, reg_loss=0.00511, lr=0.000978]\n",
      "177it [00:53,  3.29it/s, loss=-1.14, nll=-1.16, kl_latent=0.00683, kl_params=0.101, reg_loss=0.00227, lr=0.000977]\n",
      "177it [00:52,  3.35it/s, loss=-1.14, nll=-1.16, kl_latent=0.00672, kl_params=0.105, reg_loss=0.00371, lr=0.000976] \n",
      "177it [00:53,  3.33it/s, loss=-1.16, nll=-1.17, kl_latent=0.00694, kl_params=0.0933, reg_loss=0.00169, lr=0.000975]\n",
      "177it [00:52,  3.34it/s, loss=-1.18, nll=-1.2, kl_latent=0.00669, kl_params=0.0912, reg_loss=0.00308, lr=0.000974] \n",
      "177it [00:53,  3.33it/s, loss=-1.18, nll=-1.2, kl_latent=0.00665, kl_params=0.0911, reg_loss=0.00373, lr=0.000973] \n",
      "177it [00:52,  3.35it/s, loss=-1.18, nll=-1.2, kl_latent=0.00675, kl_params=0.0946, reg_loss=0.0055, lr=0.000972]  \n",
      "177it [00:52,  3.36it/s, loss=-1.19, nll=-1.21, kl_latent=0.00668, kl_params=0.0925, reg_loss=0.00196, lr=0.000971]\n",
      "177it [00:53,  3.32it/s, loss=-1.17, nll=-1.2, kl_latent=0.00659, kl_params=0.108, reg_loss=0.0103, lr=0.00097]  \n",
      "177it [00:53,  3.31it/s, loss=-1.2, nll=-1.22, kl_latent=0.00653, kl_params=0.105, reg_loss=0.00344, lr=0.000969] \n",
      "177it [00:53,  3.34it/s, loss=-1.11, nll=-1.14, kl_latent=0.0068, kl_params=0.104, reg_loss=0.0106, lr=0.000968]  \n",
      "177it [00:53,  3.32it/s, loss=-1.08, nll=-1.1, kl_latent=0.00706, kl_params=0.107, reg_loss=0.00233, lr=0.000968] \n",
      "177it [00:55,  3.21it/s, loss=-1.23, nll=-1.25, kl_latent=0.00773, kl_params=0.0887, reg_loss=0.00168, lr=0.000967]\n",
      "177it [00:53,  3.29it/s, loss=-1.25, nll=-1.27, kl_latent=0.00749, kl_params=0.091, reg_loss=0.00211, lr=0.000966] \n",
      "177it [00:53,  3.29it/s, loss=-1.26, nll=-1.28, kl_latent=0.007, kl_params=0.0893, reg_loss=0.000391, lr=0.000965]  \n",
      "177it [00:53,  3.31it/s, loss=-1.27, nll=-1.28, kl_latent=0.00663, kl_params=0.091, reg_loss=0.00105, lr=0.000964] \n",
      "177it [00:53,  3.31it/s, loss=-1.27, nll=-1.29, kl_latent=0.00653, kl_params=0.0898, reg_loss=0.00166, lr=0.000963]\n",
      "177it [00:53,  3.32it/s, loss=-1.25, nll=-1.27, kl_latent=0.00573, kl_params=0.0967, reg_loss=0.00193, lr=0.000962]\n",
      "177it [00:53,  3.30it/s, loss=-1.29, nll=-1.31, kl_latent=0.00703, kl_params=0.0889, reg_loss=0.00594, lr=0.000961]\n",
      "177it [00:53,  3.31it/s, loss=-1.26, nll=-1.28, kl_latent=0.00703, kl_params=0.0935, reg_loss=0.00354, lr=0.00096]\n",
      "177it [00:53,  3.31it/s, loss=-1.29, nll=-1.3, kl_latent=0.00661, kl_params=0.09, reg_loss=0.000979, lr=0.000959]   \n",
      "177it [00:53,  3.33it/s, loss=-1.3, nll=-1.32, kl_latent=0.0065, kl_params=0.0913, reg_loss=0.00192, lr=0.000958]  \n",
      "177it [00:53,  3.32it/s, loss=-1.32, nll=-1.34, kl_latent=0.00623, kl_params=0.0884, reg_loss=0.000536, lr=0.000957]\n",
      "177it [00:53,  3.31it/s, loss=-1.26, nll=-1.28, kl_latent=0.0061, kl_params=0.0983, reg_loss=0.00515, lr=0.000956] \n",
      "177it [00:53,  3.32it/s, loss=-1.28, nll=-1.3, kl_latent=0.0068, kl_params=0.0809, reg_loss=0.00323, lr=0.000955]  \n",
      "177it [00:53,  3.31it/s, loss=-1.29, nll=-1.31, kl_latent=0.00657, kl_params=0.0836, reg_loss=0.00239, lr=0.000954]\n",
      "177it [00:53,  3.31it/s, loss=-1.32, nll=-1.34, kl_latent=0.00645, kl_params=0.0845, reg_loss=0.000449, lr=0.000953]\n",
      "7it [00:02,  2.87it/s, loss=-1.7, nll=-1.71, kl_latent=0.00514, kl_params=0.0854, reg_loss=0, lr=0.000952] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m reg_loss \u001b[38;5;241m=\u001b[39m train_functions\u001b[38;5;241m.\u001b[39mlatent_init_loss(latent[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m nll\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39mkl_p\u001b[38;5;241m+\u001b[39mkl_z\u001b[38;5;241m+\u001b[39mreg_loss\n\u001b[0;32m---> 36\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m _history\u001b[38;5;241m.\u001b[39mbatch([loss\u001b[38;5;241m.\u001b[39mcpu(), nll\u001b[38;5;241m.\u001b[39mcpu(), kl_z\u001b[38;5;241m.\u001b[39mcpu(),kl_p\u001b[38;5;241m.\u001b[39mcpu(),reg_loss\u001b[38;5;241m.\u001b[39mcpu(), optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnll\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_latent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_params\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/torch/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtype=torch.float32\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "n_samples = 128\n",
    "epochs = 1000\n",
    "root = 'checkpoints/HHS_SIR_Big/'      \n",
    "tmax = 9\n",
    "\n",
    "eval_pts = [0, 6]\n",
    "while eval_pts[-1] < gamma-1:\n",
    "    eval_pts.append(eval_pts[-1]+7)\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    # with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        t = torch.linspace(0,tmax-1, tmax, device=device)\n",
    "    \n",
    "        pbar = tqdm.tqdm(zip(x_train, y_train))\n",
    "        for x_tr, y_tr in pbar:\n",
    "            batch_size = x_tr.shape[0]\n",
    "            eps = torch.randn(n_samples, batch_size, n_regions, latent_dim-1, dtype=dtype, device=device)\n",
    "            ode.clear_tracking()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mean, std = enc(x_tr)\n",
    "            z = reparam(eps, std, mean, n_samples, batch_size)\n",
    "            latent = odeint(ode, z, t, method='rk4', options=dict(step_size = 1.0))\n",
    "            y_pred = dec(latent[..., :3]).reshape((-1, n_samples, batch_size, n_regions)).permute(2,1,0,3)\n",
    "    \n",
    "            nll = train_functions.nll_loss(y_pred, y_tr[:, eval_pts, :])\n",
    "            \n",
    "            kl_p = train_functions.get_kl_params(1, ode.posterior(), means=means, stds = stds,limit = 1e6, device=device)\n",
    "            kl_z = kl_divergence(make_prior(mean, latent_dim=latent_dim, device=device), Normal(mean, std)).sum(-1).mean() / len(x_train)\n",
    "            reg_loss = train_functions.latent_init_loss(latent[..., :3])\n",
    "    \n",
    "            loss = nll+0.1*kl_p+kl_z+reg_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _history.batch([loss.cpu(), nll.cpu(), kl_z.cpu(),kl_p.cpu(),reg_loss.cpu(), optimizer.param_groups[-1]['lr']], ['loss', 'nll', 'kl_latent', 'kl_params', 'reg_loss', 'lr'])\n",
    "            pbar.set_postfix(_history.epoch())\n",
    "        _history.reset()\n",
    "        if epoch > 10:\n",
    "            if np.all([h['nll'] < -2 for h in _history.epoch_history[-10:]]):\n",
    "                tmax = min(tmax+1, 5)\n",
    "            \n",
    "        utils.update_learning_rate(optimizer, 0.999, lr/10)\n",
    "\n",
    "        if not os.path.exists(root):\n",
    "            os.mkdir(root)\n",
    "        torch.save(enc.state_dict(), root+'enc_' + '.pth')\n",
    "        torch.save(ode.state_dict(), root+'sir_' + '.pth')\n",
    "        torch.save(dec.state_dict(), root+'dec_' + '.pth')\n",
    "    \n",
    "    # print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "    # prof.export_chrome_trace(f\"trace_epoch_{epoch}.json\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0240fbc-4888-4b0b-bd3a-6451c186fa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.0, 1.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([h['nll'] for h in _history.epoch_history])\n",
    "plt.ylim([-2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a530bb55-fd0d-473d-a09e-77405f85d33f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[56, 128, 13, 10]' is invalid for input of size 465920",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m z \u001b[38;5;241m=\u001b[39m reparam(eps, std, mean, n_samples, batch_size)\n\u001b[1;32m     18\u001b[0m latent \u001b[38;5;241m=\u001b[39m odeint(ode, z, t, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrk4\u001b[39m\u001b[38;5;124m'\u001b[39m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_regions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     21\u001b[0m mean \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m std \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mstd(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[56, 128, 13, 10]' is invalid for input of size 465920"
     ]
    }
   ],
   "source": [
    "x_in = x_train[-1]\n",
    "y_in = y_train[-1]\n",
    "\n",
    "n_samples = 128\n",
    "dtype=torch.float32\n",
    "t = torch.linspace(1,4, 28)\n",
    "\n",
    "batch_size = x_in.shape[0]\n",
    "eps = torch.randn(n_samples, batch_size, n_regions, latent_dim-1, dtype=dtype, device=device)\n",
    "ode.clear_tracking()\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "\n",
    "mean, std = enc(x_in)\n",
    "\n",
    "z = reparam(eps, std, mean, n_samples, batch_size)\n",
    "latent = odeint(ode, z, t, method='rk4', options=dict(step_size = 1.0))\n",
    "y_pred = dec(latent[..., :3]).reshape((gamma, n_samples, batch_size, n_regions)).permute(2,1,0,3)\n",
    "\n",
    "mean = y_pred.mean(1)\n",
    "std = y_pred.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91909a88-a575-4b0b-b696-7198b098e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "std[..., 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3d9c0-a3eb-4d27-8b58-d6cb5d626bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0656fa-14e8-447b-8aae-c6159a0111b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9580ff-55c1-4421-862d-2d044b62ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 13\n",
    "\n",
    "for hhs in range(10):\n",
    "\n",
    "    plt.plot(mean[:, g, hhs].cpu().detach(), color='red')\n",
    "    plt.plot(y_in[:, g, hhs].cpu().detach())\n",
    "    \n",
    "    plt.fill_between(np.linspace(0, mean.shape[0]-1, mean.shape[0]), \n",
    "                     (std+mean)[:, g, hhs].cpu().detach(), \n",
    "                     (mean-std)[:, g, hhs].cpu().detach(), color='red', alpha=0.3, linewidth=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b042441-bdae-47d1-8f5e-61a5a679c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633bb00-a0cf-40ac-ab1a-2e1093f621c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
